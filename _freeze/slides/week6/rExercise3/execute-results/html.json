{
  "hash": "8fc87b9024aad99e59a75784eb5780d0",
  "result": {
    "markdown": "---\ntitle: Classification Basic Concepts and Techniques\n---\n\n\n## Install packages\n\nInstall the packages used in this chapter:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pacman)\n\np_load(tidyverse, rpart, rpart.plot, caret, \n  lattice, FSelector, sampling, pROC, mlbench)\n```\n:::\n\n\n\n## Introduction\n\nClassification is a machine learning task with the goal to learn a predictive function of the form\n\n$$y = f(\\mathbf{x}),$$\n\nwhere $\\mathbf{x}$ is called the attribute set and $y$ the class label. The attribute set consists of feature which describe an object. These features can be measured using any scale (i.e., nominal, interval, ...). The class label is a nominal attribute. It it is a binary attribute, then the problem is called a binary classification problem.\n\nClassification learns the classification model from training data where both the features and the correct class label are available. This is why it is called a [supervised learning problem](https://en.wikipedia.org/wiki/Supervised_learning).\n\nA related supervised learning problem is [regression](https://en.wikipedia.org/wiki/Linear_regression), where $y$ is a number instead of a label. Linear regression is a very popular supervised learning model, however, we will not talk about it here since it is taught in almost any introductory statistics course.\n\nThis chapter will introduce decision trees, model evaluation and comparison, feature selection, and then explore methods to handle the class imbalance problem.\n\nYou can read the free sample chapter from the textbook [@Tan2005]: [Chapter 3. Classification: Basic Concepts and Techniques](https://www-users.cs.umn.edu/~kumar001/dmbook/ch3_classification.pdf)\n\n## The Zoo Dataset\n\nTo demonstrate classification, we will use the Zoo dataset which is included in the R package **mlbench** (you may have to install it). The Zoo dataset containing 17 (mostly logical) variables for 101 animals as a data frame with 17 columns (hair, feathers, eggs, milk, airborne, aquatic, predator, toothed, backbone, breathes, venomous, fins, legs, tail, domestic, catsize, type). The first 16 columns represent the feature vector $\\mathbf{x}$ and the last column called type is the class label $y$. We convert the data frame into a tidyverse tibble (optional).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(Zoo, package=\"mlbench\")\nhead(Zoo)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          hair feathers  eggs  milk airborne aquatic predator toothed backbone\naardvark  TRUE    FALSE FALSE  TRUE    FALSE   FALSE     TRUE    TRUE     TRUE\nantelope  TRUE    FALSE FALSE  TRUE    FALSE   FALSE    FALSE    TRUE     TRUE\nbass     FALSE    FALSE  TRUE FALSE    FALSE    TRUE     TRUE    TRUE     TRUE\nbear      TRUE    FALSE FALSE  TRUE    FALSE   FALSE     TRUE    TRUE     TRUE\nboar      TRUE    FALSE FALSE  TRUE    FALSE   FALSE     TRUE    TRUE     TRUE\nbuffalo   TRUE    FALSE FALSE  TRUE    FALSE   FALSE    FALSE    TRUE     TRUE\n         breathes venomous  fins legs  tail domestic catsize   type\naardvark     TRUE    FALSE FALSE    4 FALSE    FALSE    TRUE mammal\nantelope     TRUE    FALSE FALSE    4  TRUE    FALSE    TRUE mammal\nbass        FALSE    FALSE  TRUE    0  TRUE    FALSE   FALSE   fish\nbear         TRUE    FALSE FALSE    4 FALSE    FALSE    TRUE mammal\nboar         TRUE    FALSE FALSE    4  TRUE    FALSE    TRUE mammal\nbuffalo      TRUE    FALSE FALSE    4  TRUE    FALSE    TRUE mammal\n```\n:::\n:::\n\n\n*Note:* data.frames in R can have row names. The Zoo data set uses the animal name as the row names. tibbles from `tidyverse` do not support row names. To keep the animal name you can add a column with the animal name.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nas_tibble(Zoo, rownames = \"animal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 101 × 18\n   animal  hair  feathers eggs  milk  airborne aquatic predator toothed backbone\n   <chr>   <lgl> <lgl>    <lgl> <lgl> <lgl>    <lgl>   <lgl>    <lgl>   <lgl>   \n 1 aardva… TRUE  FALSE    FALSE TRUE  FALSE    FALSE   TRUE     TRUE    TRUE    \n 2 antelo… TRUE  FALSE    FALSE TRUE  FALSE    FALSE   FALSE    TRUE    TRUE    \n 3 bass    FALSE FALSE    TRUE  FALSE FALSE    TRUE    TRUE     TRUE    TRUE    \n 4 bear    TRUE  FALSE    FALSE TRUE  FALSE    FALSE   TRUE     TRUE    TRUE    \n 5 boar    TRUE  FALSE    FALSE TRUE  FALSE    FALSE   TRUE     TRUE    TRUE    \n 6 buffalo TRUE  FALSE    FALSE TRUE  FALSE    FALSE   FALSE    TRUE    TRUE    \n 7 calf    TRUE  FALSE    FALSE TRUE  FALSE    FALSE   FALSE    TRUE    TRUE    \n 8 carp    FALSE FALSE    TRUE  FALSE FALSE    TRUE    FALSE    TRUE    TRUE    \n 9 catfish FALSE FALSE    TRUE  FALSE FALSE    TRUE    TRUE     TRUE    TRUE    \n10 cavy    TRUE  FALSE    FALSE TRUE  FALSE    FALSE   FALSE    TRUE    TRUE    \n# ℹ 91 more rows\n# ℹ 8 more variables: breathes <lgl>, venomous <lgl>, fins <lgl>, legs <int>,\n#   tail <lgl>, domestic <lgl>, catsize <lgl>, type <fct>\n```\n:::\n:::\n\n\nYou will have to remove the animal column before learning a model! In the following I use the data.frame.\n\nI translate all the TRUE/FALSE values into factors (nominal). This is often needed for building models. Always check `summary()` to make sure the data is ready for model learning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nZoo <- Zoo |>\n  mutate(across(where(is.logical), factor, levels = c(TRUE, FALSE))) |>\n  mutate(across(where(is.character), factor))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.logical), factor, levels = c(TRUE, FALSE))`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n```\n:::\n\n```{.r .cell-code}\nsummary(Zoo)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    hair     feathers     eggs       milk     airborne   aquatic    predator \n TRUE :43   TRUE :20   TRUE :59   TRUE :41   TRUE :24   TRUE :36   TRUE :56  \n FALSE:58   FALSE:81   FALSE:42   FALSE:60   FALSE:77   FALSE:65   FALSE:45  \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n  toothed    backbone   breathes   venomous     fins         legs      \n TRUE :61   TRUE :83   TRUE :80   TRUE : 8   TRUE :17   Min.   :0.000  \n FALSE:40   FALSE:18   FALSE:21   FALSE:93   FALSE:84   1st Qu.:2.000  \n                                                        Median :4.000  \n                                                        Mean   :2.842  \n                                                        3rd Qu.:4.000  \n                                                        Max.   :8.000  \n                                                                       \n    tail     domestic   catsize              type   \n TRUE :75   TRUE :13   TRUE :44   mammal       :41  \n FALSE:26   FALSE:88   FALSE:57   bird         :20  \n                                  reptile      : 5  \n                                  fish         :13  \n                                  amphibian    : 4  \n                                  insect       : 8  \n                                  mollusc.et.al:10  \n```\n:::\n:::\n\n\n## Decision Trees\n\nRecursive Partitioning (similar to CART) uses the Gini index to make splitting decisions and early stopping (pre-pruning).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rpart)\n```\n:::\n\n\n### Create Tree With Default Settings (uses pre-pruning)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_default <- Zoo |> \n  rpart(type ~ ., data = _)\ntree_default\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nn= 101 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 101 60 mammal (0.41 0.2 0.05 0.13 0.04 0.079 0.099)  \n   2) milk=TRUE 41  0 mammal (1 0 0 0 0 0 0) *\n   3) milk=FALSE 60 40 bird (0 0.33 0.083 0.22 0.067 0.13 0.17)  \n     6) feathers=TRUE 20  0 bird (0 1 0 0 0 0 0) *\n     7) feathers=FALSE 40 27 fish (0 0 0.12 0.33 0.1 0.2 0.25)  \n      14) fins=TRUE 13  0 fish (0 0 0 1 0 0 0) *\n      15) fins=FALSE 27 17 mollusc.et.al (0 0 0.19 0 0.15 0.3 0.37)  \n        30) backbone=TRUE 9  4 reptile (0 0 0.56 0 0.44 0 0) *\n        31) backbone=FALSE 18  8 mollusc.et.al (0 0 0 0 0 0.44 0.56) *\n```\n:::\n:::\n\n\n**Notes:**\n\n-   `|>` supplies the data for `rpart`. Since `data` is not the first argument of `rpart`, the syntax `data = _` is used to specify where the data in `Zoo` goes. The call is equivalent to `tree_default <- rpart(type ~ ., data = Zoo)`.\n\n-   The formula models the `type` variable by all other features is represented by `.`.\n\n-   the class variable needs a factor (nominal) or rpart will create a regression tree instead of a decision tree. Use `as.factor()` if necessary.\n\nPlotting\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rpart.plot)\nrpart.plot(tree_default, extra = 2)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n*Note:* `extra=2` prints for each leaf node the number of correctly classified objects from data and the total number of objects from the training data falling into that node (correct/total).\n\n### Create a Full Tree\n\nTo create a full tree, we set the complexity parameter cp to 0 (split even if it does not improve the tree) and we set the minimum number of observations in a node needed to split to the smallest value of 2 (see: `?rpart.control`). *Note:* full trees overfit the training data!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_full <- Zoo |> \n  rpart(type ~ . , data = _, \n        control = rpart.control(minsplit = 2, cp = 0))\nrpart.plot(tree_full, extra = 2, \n           roundint=FALSE,\n            box.palette = list(\"Gy\", \"Gn\", \"Bu\", \"Bn\", \n                               \"Or\", \"Rd\", \"Pu\")) # specify 7 colors\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntree_full\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nn= 101 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 101 60 mammal (0.41 0.2 0.05 0.13 0.04 0.079 0.099)  \n    2) milk=TRUE 41  0 mammal (1 0 0 0 0 0 0) *\n    3) milk=FALSE 60 40 bird (0 0.33 0.083 0.22 0.067 0.13 0.17)  \n      6) feathers=TRUE 20  0 bird (0 1 0 0 0 0 0) *\n      7) feathers=FALSE 40 27 fish (0 0 0.12 0.33 0.1 0.2 0.25)  \n       14) fins=TRUE 13  0 fish (0 0 0 1 0 0 0) *\n       15) fins=FALSE 27 17 mollusc.et.al (0 0 0.19 0 0.15 0.3 0.37)  \n         30) backbone=TRUE 9  4 reptile (0 0 0.56 0 0.44 0 0)  \n           60) aquatic=FALSE 4  0 reptile (0 0 1 0 0 0 0) *\n           61) aquatic=TRUE 5  1 amphibian (0 0 0.2 0 0.8 0 0)  \n            122) eggs=FALSE 1  0 reptile (0 0 1 0 0 0 0) *\n            123) eggs=TRUE 4  0 amphibian (0 0 0 0 1 0 0) *\n         31) backbone=FALSE 18  8 mollusc.et.al (0 0 0 0 0 0.44 0.56)  \n           62) airborne=TRUE 6  0 insect (0 0 0 0 0 1 0) *\n           63) airborne=FALSE 12  2 mollusc.et.al (0 0 0 0 0 0.17 0.83)  \n            126) predator=FALSE 4  2 insect (0 0 0 0 0 0.5 0.5)  \n              252) legs>=3 2  0 insect (0 0 0 0 0 1 0) *\n              253) legs< 3 2  0 mollusc.et.al (0 0 0 0 0 0 1) *\n            127) predator=TRUE 8  0 mollusc.et.al (0 0 0 0 0 0 1) *\n```\n:::\n:::\n\n\nTraining error on tree with pre-pruning\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(tree_default, Zoo) |> head ()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         mammal bird reptile fish amphibian insect mollusc.et.al\naardvark      1    0       0    0         0      0             0\nantelope      1    0       0    0         0      0             0\nbass          0    0       0    1         0      0             0\nbear          1    0       0    0         0      0             0\nboar          1    0       0    0         0      0             0\nbuffalo       1    0       0    0         0      0             0\n```\n:::\n\n```{.r .cell-code}\npred <- predict(tree_default, Zoo, type=\"class\")\nhead(pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\naardvark antelope     bass     bear     boar  buffalo \n  mammal   mammal     fish   mammal   mammal   mammal \nLevels: mammal bird reptile fish amphibian insect mollusc.et.al\n```\n:::\n\n```{.r .cell-code}\nconfusion_table <- with(Zoo, table(type, pred))\nconfusion_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               pred\ntype            mammal bird reptile fish amphibian insect mollusc.et.al\n  mammal            41    0       0    0         0      0             0\n  bird               0   20       0    0         0      0             0\n  reptile            0    0       5    0         0      0             0\n  fish               0    0       0   13         0      0             0\n  amphibian          0    0       4    0         0      0             0\n  insect             0    0       0    0         0      0             8\n  mollusc.et.al      0    0       0    0         0      0            10\n```\n:::\n\n```{.r .cell-code}\ncorrect <- confusion_table |> diag() |> sum()\ncorrect\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 89\n```\n:::\n\n```{.r .cell-code}\nerror <- confusion_table |> sum() - correct\nerror\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12\n```\n:::\n\n```{.r .cell-code}\naccuracy <- correct / (correct + error)\naccuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8811881\n```\n:::\n:::\n\n\nUse a function for accuracy\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy <- function(truth, prediction) {\n    tbl <- table(truth, prediction)\n    sum(diag(tbl))/sum(tbl)\n}\n\naccuracy(Zoo |> pull(type), pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8811881\n```\n:::\n:::\n\n\nTraining error of the full tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(Zoo |> pull(type), \n         predict(tree_full, Zoo, type = \"class\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\n\nGet a confusion table with more statistics (using caret)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nconfusionMatrix(data = pred, \n                reference = Zoo |> pull(type))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      mammal bird reptile fish amphibian insect mollusc.et.al\n  mammal            41    0       0    0         0      0             0\n  bird               0   20       0    0         0      0             0\n  reptile            0    0       5    0         4      0             0\n  fish               0    0       0   13         0      0             0\n  amphibian          0    0       0    0         0      0             0\n  insect             0    0       0    0         0      0             0\n  mollusc.et.al      0    0       0    0         0      8            10\n\nOverall Statistics\n                                          \n               Accuracy : 0.8812          \n                 95% CI : (0.8017, 0.9371)\n    No Information Rate : 0.4059          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8431          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: mammal Class: bird Class: reptile Class: fish\nSensitivity                 1.0000       1.000        1.00000      1.0000\nSpecificity                 1.0000       1.000        0.95833      1.0000\nPos Pred Value              1.0000       1.000        0.55556      1.0000\nNeg Pred Value              1.0000       1.000        1.00000      1.0000\nPrevalence                  0.4059       0.198        0.04950      0.1287\nDetection Rate              0.4059       0.198        0.04950      0.1287\nDetection Prevalence        0.4059       0.198        0.08911      0.1287\nBalanced Accuracy           1.0000       1.000        0.97917      1.0000\n                     Class: amphibian Class: insect Class: mollusc.et.al\nSensitivity                    0.0000       0.00000              1.00000\nSpecificity                    1.0000       1.00000              0.91209\nPos Pred Value                    NaN           NaN              0.55556\nNeg Pred Value                 0.9604       0.92079              1.00000\nPrevalence                     0.0396       0.07921              0.09901\nDetection Rate                 0.0000       0.00000              0.09901\nDetection Prevalence           0.0000       0.00000              0.17822\nBalanced Accuracy              0.5000       0.50000              0.95604\n```\n:::\n:::\n\n\n### Make Predictions for New Data\n\nMake up my own animal: A lion with feathered wings\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_animal <- tibble(hair = TRUE, feathers = TRUE, eggs = FALSE,\n  milk = TRUE, airborne = TRUE, aquatic = FALSE, predator = TRUE,\n  toothed = TRUE, backbone = TRUE, breathes = TRUE, venomous = FALSE,\n  fins = FALSE, legs = 4, tail = TRUE, domestic = FALSE,\n  catsize = FALSE, type = NA)\n```\n:::\n\n\nFix columns to be factors like in the training set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_animal <- my_animal |> \n  mutate(across(where(is.logical), factor, levels = c(TRUE, FALSE)))\nmy_animal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 17\n  hair  feathers eggs  milk  airborne aquatic predator toothed backbone breathes\n  <fct> <fct>    <fct> <fct> <fct>    <fct>   <fct>    <fct>   <fct>    <fct>   \n1 TRUE  TRUE     FALSE TRUE  TRUE     FALSE   TRUE     TRUE    TRUE     TRUE    \n# ℹ 7 more variables: venomous <fct>, fins <fct>, legs <dbl>, tail <fct>,\n#   domestic <fct>, catsize <fct>, type <fct>\n```\n:::\n:::\n\n\nMake a prediction using the default tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(tree_default , my_animal, type = \"class\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     1 \nmammal \nLevels: mammal bird reptile fish amphibian insect mollusc.et.al\n```\n:::\n:::\n\n\n## Model Evaluation with Caret\n\nThe package [`caret`](https://topepo.github.io/caret/) makes preparing training sets, building classification (and regression) models and evaluation easier. A great cheat sheet can be found [here](https://ugoproto.github.io/ugo_r_doc/pdf/caret.pdf).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n:::\n\n\nCross-validation runs are independent and can be done faster in parallel. To enable multi-core support, `caret` uses the package `foreach` and you need to load a `do` backend. For Linux, you can use `doMC` with 4 cores. Windows needs different backend like `doParallel` (see `caret` cheat sheet above).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Linux backend\n# library(doMC)\n# registerDoMC(cores = 4)\n# getDoParWorkers()\n\n## Windows backend\n# library(doParallel)\n# cl <- makeCluster(4, type=\"SOCK\")\n# registerDoParallel(cl)\n```\n:::\n\n\nSet random number generator seed to make results reproducible\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2000)\n```\n:::\n\n\n### Hold out Test Data\n\nTest data is not used in the model building process and set aside purely for testing the model. Here, we partition data the 80% training and 20% testing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninTrain <- createDataPartition(y = Zoo$type, p = .8, list = FALSE)\nZoo_train <- Zoo |> slice(inTrain)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Slicing with a 1-column matrix was deprecated in dplyr 1.1.0.\n```\n:::\n\n```{.r .cell-code}\nZoo_test <- Zoo |> slice(-inTrain)\n```\n:::\n\n\n### Learn a Model and Tune Hyperparameters on the Training Data\n\nThe package `caret` combines training and validation for hyperparameter tuning into a single function called `train()`. It internally splits the data into training and validation sets and thus will provide you with error estimates for different hyperparameter settings. `trainControl` is used to choose how testing is performed.\n\nFor rpart, train tries to tune the `cp` parameter (tree complexity) using accuracy to chose the best model. I set `minsplit` to 2 since we have not much data. **Note:** Parameters used for tuning (in this case `cp`) need to be set using a data.frame in the argument `tuneGrid`! Setting it in control will be ignored.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- Zoo_train |>\n  train(type ~ .,\n    data = _ ,\n    method = \"rpart\",\n    control = rpart.control(minsplit = 2),\n    trControl = trainControl(method = \"cv\", number = 10),\n    tuneLength = 5)\n\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n83 samples\n16 predictors\n 7 classes: 'mammal', 'bird', 'reptile', 'fish', 'amphibian', 'insect', 'mollusc.et.al' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 77, 74, 75, 73, 74, 76, ... \nResampling results across tuning parameters:\n\n  cp    Accuracy   Kappa    \n  0.00  0.9384921  0.9188571\n  0.08  0.8973810  0.8681837\n  0.16  0.7447619  0.6637060\n  0.22  0.6663095  0.5540490\n  0.32  0.4735317  0.1900043\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.\n```\n:::\n:::\n\n\n**Note:** Train has built 10 trees using the training folds for each value of `cp` and the reported values for accuracy and Kappa are the averages on the validation folds.\n\nA model using the best tuning parameters and using all the data supplied to `train()` is available as `fit$finalModel`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrpart.plot(fit$finalModel, extra = 2,\n  box.palette = list(\"Gy\", \"Gn\", \"Bu\", \"Bn\", \"Or\", \"Rd\", \"Pu\"))\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\ncaret also computes variable importance. By default it uses competing splits (splits which would be runners up, but do not get chosen by the tree) for rpart models (see `? varImp`). Toothed is the runner up for many splits, but it never gets chosen!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvarImp(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nrpart variable importance\n\n              Overall\ntoothedFALSE  100.000\nfeathersFALSE  69.814\nbackboneFALSE  63.084\nmilkFALSE      55.555\neggsFALSE      53.614\nhairFALSE      50.518\nfinsFALSE      46.984\ntailFALSE      28.447\nbreathesFALSE  28.128\nairborneFALSE  26.272\nlegs           25.859\naquaticFALSE    5.960\npredatorFALSE   2.349\nvenomousFALSE   1.387\ncatsizeFALSE    0.000\ndomesticFALSE   0.000\n```\n:::\n:::\n\n\nHere is the variable importance without competing splits.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp <- varImp(fit, compete = FALSE)\nimp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nrpart variable importance\n\n              Overall\nmilkFALSE     100.000\nfeathersFALSE  55.694\nfinsFALSE      39.453\ntoothedFALSE   22.956\nairborneFALSE  22.478\naquaticFALSE    9.987\neggsFALSE       6.658\nlegs            5.549\npredatorFALSE   1.850\ndomesticFALSE   0.000\nbreathesFALSE   0.000\ncatsizeFALSE    0.000\ntailFALSE       0.000\nhairFALSE       0.000\nbackboneFALSE   0.000\nvenomousFALSE   0.000\n```\n:::\n\n```{.r .cell-code}\nggplot(imp)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n**Note:** Not all models provide a variable importance function. In this case caret might calculate the variable importance by itself and ignore the model (see `? varImp`)!\n\n## Testing: Confusion Matrix and Confidence Interval for Accuracy\n\nUse the best model on the test data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred <- predict(fit, newdata = Zoo_test)\npred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] mammal        mammal        mollusc.et.al insect        mammal       \n [6] mammal        mammal        bird          mammal        mammal       \n[11] bird          fish          fish          mammal        mollusc.et.al\n[16] bird          insect        bird         \nLevels: mammal bird reptile fish amphibian insect mollusc.et.al\n```\n:::\n:::\n\n\nCaret's `confusionMatrix()` function calculates accuracy, confidence intervals, kappa and many more evaluation metrics. You need to use separate test data to create a confusion matrix based on the generalization error.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(data = pred, \n                ref = Zoo_test |> pull(type))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      mammal bird reptile fish amphibian insect mollusc.et.al\n  mammal             8    0       0    0         0      0             0\n  bird               0    4       0    0         0      0             0\n  reptile            0    0       0    0         0      0             0\n  fish               0    0       0    2         0      0             0\n  amphibian          0    0       0    0         0      0             0\n  insect             0    0       1    0         0      1             0\n  mollusc.et.al      0    0       0    0         0      0             2\n\nOverall Statistics\n                                          \n               Accuracy : 0.9444          \n                 95% CI : (0.7271, 0.9986)\n    No Information Rate : 0.4444          \n    P-Value [Acc > NIR] : 1.076e-05       \n                                          \n                  Kappa : 0.9231          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: mammal Class: bird Class: reptile Class: fish\nSensitivity                 1.0000      1.0000        0.00000      1.0000\nSpecificity                 1.0000      1.0000        1.00000      1.0000\nPos Pred Value              1.0000      1.0000            NaN      1.0000\nNeg Pred Value              1.0000      1.0000        0.94444      1.0000\nPrevalence                  0.4444      0.2222        0.05556      0.1111\nDetection Rate              0.4444      0.2222        0.00000      0.1111\nDetection Prevalence        0.4444      0.2222        0.00000      0.1111\nBalanced Accuracy           1.0000      1.0000        0.50000      1.0000\n                     Class: amphibian Class: insect Class: mollusc.et.al\nSensitivity                        NA       1.00000               1.0000\nSpecificity                         1       0.94118               1.0000\nPos Pred Value                     NA       0.50000               1.0000\nNeg Pred Value                     NA       1.00000               1.0000\nPrevalence                          0       0.05556               0.1111\nDetection Rate                      0       0.05556               0.1111\nDetection Prevalence                0       0.11111               0.1111\nBalanced Accuracy                  NA       0.97059               1.0000\n```\n:::\n:::\n\n\n**Some notes**\n\n-   Many classification algorithms and `train` in caret do not deal well with missing values. If your classification model can deal with missing values (e.g., `rpart`) then use `na.action = na.pass` when you call `train` and `predict`. Otherwise, you need to remove observations with missing values with `na.omit` or use imputation to replace the missing values before you train the model. Make sure that you still have enough observations left.\n-   Make sure that nominal variables (this includes logical variables) are coded as factors.\n-   The class variable for train in caret cannot have level names that are keywords in R (e.g., `TRUE` and `FALSE`). Rename them to, for example, \"yes\" and \"no.\"\n-   Make sure that nominal variables (factors) have examples for all possible values. Some methods might have problems with variable values without examples. You can drop empty levels using `droplevels` or `factor`.\n-   Sampling in train might create a sample that does not contain examples for all values in a nominal (factor) variable. You will get an error message. This most likely happens for variables which have one very rare value. You may have to remove the variable.\n\n## Model Comparison\n\nWe will compare decision trees with a k-nearest neighbors (kNN) classifier. We will create fixed sampling scheme (10-folds) so we compare the different models using exactly the same folds. It is specified as `trControl` during training.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_index <- createFolds(Zoo_train$type, k = 10)\n```\n:::\n\n\nBuild models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrpartFit <- Zoo_train |> \n  train(type ~ .,\n        data = _,\n        method = \"rpart\",\n        tuneLength = 10,\n        trControl = trainControl(method = \"cv\", indexOut = train_index)\n  )\n```\n:::\n\n\n**Note:** for kNN we ask `train` to scale the data using `preProcess = \"scale\"`. Logicals will be used as 0-1 variables in Euclidean distance calculation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknnFit <- Zoo_train |> \n  train(type ~ .,\n        data = _,\n        method = \"knn\",\n        preProcess = \"scale\",\n\t      tuneLength = 10,\n\t      trControl = trainControl(method = \"cv\", indexOut = train_index)\n  )\n```\n:::\n\n\nCompare accuracy over all folds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamps <- resamples(list(\n\t\tCART = rpartFit,\n\t\tkNearestNeighbors = knnFit\n\t\t))\n\nsummary(resamps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nsummary.resamples(object = resamps)\n\nModels: CART, kNearestNeighbors \nNumber of resamples: 10 \n\nAccuracy \n                       Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA's\nCART              0.6666667 0.8750000 0.8888889 0.8722222 0.8888889    1    0\nkNearestNeighbors 0.8750000 0.9166667 1.0000000 0.9652778 1.0000000    1    0\n\nKappa \n                       Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA's\nCART              0.5909091 0.8333333 0.8474576 0.8341866 0.8570312    1    0\nkNearestNeighbors 0.8333333 0.8977273 1.0000000 0.9546970 1.0000000    1    0\n```\n:::\n:::\n\n\n`caret` provides some visualizations using the package `lattice`. For example, a boxplot to compare the accuracy and kappa distribution (over the 10 folds).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lattice)\nbwplot(resamps, layout = c(3, 1))\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nWe see that kNN is performing consistently better on the folds than CART (except for some outlier folds).\n\nFind out if one models is statistically better than the other (is the difference in accuracy is not zero).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndifs <- diff(resamps)\ndifs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\ndiff.resamples(x = resamps)\n\nModels: CART, kNearestNeighbors \nMetrics: Accuracy, Kappa \nNumber of differences: 1 \np-value adjustment: bonferroni \n```\n:::\n\n```{.r .cell-code}\nsummary(difs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nsummary.diff.resamples(object = difs)\n\np-value adjustment: bonferroni \nUpper diagonal: estimates of the difference\nLower diagonal: p-value for H0: difference = 0\n\nAccuracy \n                  CART    kNearestNeighbors\nCART                      -0.09306         \nkNearestNeighbors 0.01151                  \n\nKappa \n                  CART   kNearestNeighbors\nCART                     -0.1205          \nkNearestNeighbors 0.0104                  \n```\n:::\n:::\n\n\np-values tells you the probability of seeing an even more extreme value (difference between accuracy) given that the null hypothesis (difference = 0) is true. For a better classifier, the p-value should be less than .05 or 0.01. `diff` automatically applies Bonferroni correction for multiple comparisons. In this case, kNN seems better but the classifiers do not perform statistically differently.\n\n## Feature Selection and Feature Preparation\n\nDecision trees implicitly select features for splitting, but we can also select features manually.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(FSelector)\n```\n:::\n\n\nsee: <http://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Dimensionality_Reduction/Feature_Selection#The_Feature_Ranking_Approach>\n\n### Univariate Feature Importance Score\n\nThese scores measure how related each feature is to the class variable. For discrete features (as in our case), the chi-square statistic can be used to derive a score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweights <- Zoo_train |> \n  chi.squared(type ~ ., data = _) |>\n  as_tibble(rownames = \"feature\") |>\n  arrange(desc(attr_importance))\n\nweights\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16 × 2\n   feature  attr_importance\n   <chr>              <dbl>\n 1 feathers           1    \n 2 backbone           1    \n 3 milk               1    \n 4 toothed            0.975\n 5 eggs               0.933\n 6 hair               0.907\n 7 breathes           0.898\n 8 airborne           0.848\n 9 fins               0.845\n10 legs               0.828\n11 tail               0.779\n12 catsize            0.664\n13 aquatic            0.655\n14 venomous           0.475\n15 predator           0.385\n16 domestic           0.231\n```\n:::\n:::\n\n\nplot importance in descending order (using `reorder` to order factor levels used by `ggplot`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weights,\n  aes(x = attr_importance, y = reorder(feature, attr_importance))) +\n  geom_bar(stat = \"identity\") +\n  xlab(\"Importance score\") + \n  ylab(\"Feature\")\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\nGet the 5 best features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubset <- cutoff.k(weights |> \n                   column_to_rownames(\"feature\"), 5)\nsubset\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"feathers\" \"backbone\" \"milk\"     \"toothed\"  \"eggs\"    \n```\n:::\n:::\n\n\nUse only the best 5 features to build a model (`Fselector` provides `as.simple.formula`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- as.simple.formula(subset, \"type\")\nf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntype ~ feathers + backbone + milk + toothed + eggs\n<environment: 0x1435b8200>\n```\n:::\n\n```{.r .cell-code}\nm <- Zoo_train |> rpart(f, data = _)\nrpart.plot(m, extra = 2, roundint = FALSE)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\nThere are many alternative ways to calculate univariate importance scores (see package FSelector). Some of them (also) work for continuous features. One example is the information gain ratio based on entropy as used in decision tree induction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nZoo_train |> \n  gain.ratio(type ~ ., data = _) |>\n  as_tibble(rownames = \"feature\") |>\n  arrange(desc(attr_importance))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16 × 2\n   feature  attr_importance\n   <chr>              <dbl>\n 1 backbone          1     \n 2 milk              1.00  \n 3 feathers          1.00  \n 4 toothed           0.919 \n 5 eggs              0.827 \n 6 breathes          0.821 \n 7 hair              0.782 \n 8 fins              0.689 \n 9 legs              0.682 \n10 airborne          0.671 \n11 tail              0.573 \n12 aquatic           0.391 \n13 catsize           0.383 \n14 venomous          0.351 \n15 predator          0.125 \n16 domestic          0.0975\n```\n:::\n:::\n\n\n### Feature Subset Selection\n\nOften features are related and calculating importance for each feature independently is not optimal. We can use greedy search heuristics. For example `cfs` uses correlation/entropy with best first search.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nZoo_train |> \n  cfs(type ~ ., data = _)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"hair\"     \"feathers\" \"eggs\"     \"milk\"     \"toothed\"  \"backbone\"\n [7] \"breathes\" \"fins\"     \"legs\"     \"tail\"    \n```\n:::\n:::\n\n\nBlack-box feature selection uses an evaluator function (the black box) to calculate a score to be maximized. First, we define an evaluation function that builds a model given a subset of features and calculates a quality score. We use here the average for 5 bootstrap samples (`method = \"cv\"` can also be used instead), no tuning (to be faster), and the average accuracy as the score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevaluator <- function(subset) {\n  model <- Zoo_train |> \n    train(as.simple.formula(subset, \"type\"),\n          data = _,\n          method = \"rpart\",\n          trControl = trainControl(method = \"boot\", number = 5),\n          tuneLength = 0)\n  results <- model$resample$Accuracy\n  cat(\"Trying features:\", paste(subset, collapse = \" + \"), \"\\n\")\n  m <- mean(results)\n  cat(\"Accuracy:\", round(m, 2), \"\\n\\n\")\n  m\n}\n```\n:::\n\n\nStart with all features (but not the class variable `type`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeatures <- Zoo_train |> colnames() |> setdiff(\"type\")\n```\n:::\n\n\nThere are several (greedy) search strategies available. These run for a while!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##subset <- backward.search(features, evaluator)\n##subset <- forward.search(features, evaluator)\n##subset <- best.first.search(features, evaluator)\n##subset <- hill.climbing.search(features, evaluator)\n##subset\n```\n:::\n\n\n### Using Dummy Variables for Factors\n\nNominal features (factors) are often encoded as a series of 0-1 dummy variables. For example, let us try to predict if an animal is a predator given the type. First we use the original encoding of type as a factor with several values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_predator <- Zoo_train |> \n  rpart(predator ~ type, data = _)\nrpart.plot(tree_predator, extra = 2, roundint = FALSE)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\n**Note:** Some splits use multiple values. Building the tree will become extremely slow if a factor has many levels (different values) since the tree has to check all possible splits into two subsets. This situation should be avoided.\n\nConvert type into a set of 0-1 dummy variables using `class2ind`. See also `? dummyVars` in package `caret`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nZoo_train_dummy <- as_tibble(class2ind(Zoo_train$type)) |> \n  mutate(across(everything(), as.factor)) |>\n  add_column(predator = Zoo_train$predator)\nZoo_train_dummy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 83 × 8\n   mammal bird  reptile fish  amphibian insect mollusc.et.al predator\n   <fct>  <fct> <fct>   <fct> <fct>     <fct>  <fct>         <fct>   \n 1 1      0     0       0     0         0      0             TRUE    \n 2 1      0     0       0     0         0      0             FALSE   \n 3 0      0     0       1     0         0      0             TRUE    \n 4 1      0     0       0     0         0      0             TRUE    \n 5 1      0     0       0     0         0      0             FALSE   \n 6 1      0     0       0     0         0      0             FALSE   \n 7 0      0     0       1     0         0      0             FALSE   \n 8 0      0     0       1     0         0      0             TRUE    \n 9 1      0     0       0     0         0      0             FALSE   \n10 0      1     0       0     0         0      0             FALSE   \n# ℹ 73 more rows\n```\n:::\n\n```{.r .cell-code}\ntree_predator <- Zoo_train_dummy |> \n  rpart(predator ~ ., \n        data = _,\n        control = rpart.control(minsplit = 2, cp = 0.01))\nrpart.plot(tree_predator, roundint = FALSE)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\nUsing `caret` on the original factor encoding automatically translates factors (here type) into 0-1 dummy variables (e.g., `typeinsect = 0`). The reason is that some models cannot directly use factors and `caret` tries to consistently work with all of them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- Zoo_train |> \n  train(predator ~ type, \n        data = _, \n        method = \"rpart\",\n        control = rpart.control(minsplit = 2),\n        tuneGrid = data.frame(cp = 0.01))\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n83 samples\n 1 predictor\n 2 classes: 'TRUE', 'FALSE' \n\nNo pre-processing\nResampling: Bootstrapped (25 reps) \nSummary of sample sizes: 83, 83, 83, 83, 83, 83, ... \nResampling results:\n\n  Accuracy   Kappa    \n  0.6060423  0.2034198\n\nTuning parameter 'cp' was held constant at a value of 0.01\n```\n:::\n\n```{.r .cell-code}\nrpart.plot(fit$finalModel, extra = 2)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n*Note:* To use a fixed value for the tuning parameter `cp`, we have to create a tuning grid that only contains that value.\n\n## Class Imbalance\n\nClassifiers have a hard time to learn from data where we have much more observations for one class (called the majority class). This is called the class imbalance problem.\n\nHere is a very good [article about the problem and solutions.](http://www.kdnuggets.com/2016/08/learning-from-imbalanced-classes.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rpart)\nlibrary(rpart.plot)\ndata(Zoo, package=\"mlbench\")\n```\n:::\n\n\nClass distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(Zoo, aes(y = type)) + geom_bar()\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\nTo create an imbalanced problem, we want to decide if an animal is an reptile. First, we change the class variable to make it into a binary reptile/no reptile classification problem. **Note:** We use here the training data for testing. You should use a separate testing data set!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nZoo_reptile <- Zoo |> \n  mutate(type = factor(Zoo$type == \"reptile\", \n                       levels = c(FALSE, TRUE),\n                       labels = c(\"nonreptile\", \"reptile\")))\n```\n:::\n\n\nDo not forget to make the class variable a factor (a nominal variable) or you will get a regression tree instead of a classification tree.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(Zoo_reptile)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    hair          feathers          eggs            milk        \n Mode :logical   Mode :logical   Mode :logical   Mode :logical  \n FALSE:58        FALSE:81        FALSE:42        FALSE:60       \n TRUE :43        TRUE :20        TRUE :59        TRUE :41       \n                                                                \n                                                                \n                                                                \n  airborne        aquatic         predator        toothed       \n Mode :logical   Mode :logical   Mode :logical   Mode :logical  \n FALSE:77        FALSE:65        FALSE:45        FALSE:40       \n TRUE :24        TRUE :36        TRUE :56        TRUE :61       \n                                                                \n                                                                \n                                                                \n  backbone        breathes        venomous          fins        \n Mode :logical   Mode :logical   Mode :logical   Mode :logical  \n FALSE:18        FALSE:21        FALSE:93        FALSE:84       \n TRUE :83        TRUE :80        TRUE :8         TRUE :17       \n                                                                \n                                                                \n                                                                \n      legs          tail          domestic        catsize       \n Min.   :0.000   Mode :logical   Mode :logical   Mode :logical  \n 1st Qu.:2.000   FALSE:26        FALSE:88        FALSE:57       \n Median :4.000   TRUE :75        TRUE :13        TRUE :44       \n Mean   :2.842                                                  \n 3rd Qu.:4.000                                                  \n Max.   :8.000                                                  \n         type   \n nonreptile:96  \n reptile   : 5  \n                \n                \n                \n                \n```\n:::\n:::\n\n\nSee if we have a class imbalance problem.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(Zoo_reptile, aes(y = type)) + geom_bar()\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n:::\n\n\nCreate test and training data. I use here a 50/50 split to make sure that the test set has some samples of the rare reptile class.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ninTrain <- createDataPartition(y = Zoo_reptile$type, p = .5, list = FALSE)\ntraining_reptile <- Zoo_reptile |> slice(inTrain)\ntesting_reptile <- Zoo_reptile |> slice(-inTrain)\n```\n:::\n\n\nthe new class variable is clearly not balanced. This is a problem for building a tree!\n\n### Option 1: Use the Data As Is and Hope For The Best\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- training_reptile |> \n  train(type ~ .,\n        data = _,\n        method = \"rpart\",\n        trControl = trainControl(method = \"cv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n```\n:::\n:::\n\n\n**Warnings:** \"There were missing values in resampled performance measures.\" means that some test folds did not contain examples of both classes. This is very likely with class imbalance and small datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n51 samples\n16 predictors\n 2 classes: 'nonreptile', 'reptile' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 46, 47, 46, 46, 45, 46, ... \nResampling results:\n\n  Accuracy   Kappa\n  0.9466667  0    \n\nTuning parameter 'cp' was held constant at a value of 0\n```\n:::\n\n```{.r .cell-code}\nrpart.plot(fit$finalModel, extra = 2)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-51-1.png){width=672}\n:::\n:::\n\n\nthe tree predicts everything as non-reptile. Have a look at the error on the test set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(data = predict(fit, testing_reptile),\n                ref = testing_reptile$type, positive = \"reptile\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   nonreptile reptile\n  nonreptile         48       2\n  reptile             0       0\n                                          \n               Accuracy : 0.96            \n                 95% CI : (0.8629, 0.9951)\n    No Information Rate : 0.96            \n    P-Value [Acc > NIR] : 0.6767          \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : 0.4795          \n                                          \n            Sensitivity : 0.00            \n            Specificity : 1.00            \n         Pos Pred Value :  NaN            \n         Neg Pred Value : 0.96            \n             Prevalence : 0.04            \n         Detection Rate : 0.00            \n   Detection Prevalence : 0.00            \n      Balanced Accuracy : 0.50            \n                                          \n       'Positive' Class : reptile         \n                                          \n```\n:::\n:::\n\n\nAccuracy is high, but it is exactly the same as the no-information rate and kappa is zero. Sensitivity is also zero, meaning that we do not identify any positive (reptile). If the cost of missing a positive is much larger than the cost associated with misclassifying a negative, then accuracy is not a good measure! By dealing with imbalance, we are **not** concerned with accuracy, but we want to increase the sensitivity, i.e., the chance to identify positive examples.\n\n**Note:** The positive class value (the one that you want to detect) is set manually to reptile using `positive = \"reptile\"`. Otherwise sensitivity/specificity will not be correctly calculated.\n\n### Option 2: Balance Data With Resampling\n\nWe use stratified sampling with replacement (to oversample the minority/positive class). You could also use SMOTE (in package **DMwR**) or other sampling strategies (e.g., from package **unbalanced**). We use 50+50 observations here (**Note:** many samples will be chosen several times).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sampling)\nset.seed(1000) # for repeatability\n\nid <- strata(training_reptile, stratanames = \"type\", size = c(50, 50), method = \"srswr\")\ntraining_reptile_balanced <- training_reptile |> \n  slice(id$ID_unit)\ntable(training_reptile_balanced$type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nnonreptile    reptile \n        50         50 \n```\n:::\n\n```{.r .cell-code}\nfit <- training_reptile_balanced |> \n  train(type ~ .,\n        data = _,\n        method = \"rpart\",\n        trControl = trainControl(method = \"cv\"),\n        control = rpart.control(minsplit = 5))\n\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n100 samples\n 16 predictor\n  2 classes: 'nonreptile', 'reptile' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 90, 90, 90, 90, 90, 90, ... \nResampling results across tuning parameters:\n\n  cp    Accuracy  Kappa\n  0.22  0.78      0.56 \n  0.26  0.67      0.34 \n  0.34  0.54      0.08 \n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.22.\n```\n:::\n\n```{.r .cell-code}\nrpart.plot(fit$finalModel, extra = 2)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-53-1.png){width=672}\n:::\n:::\n\n\nCheck on the unbalanced testing data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(data = predict(fit, testing_reptile),\n                ref = testing_reptile$type, positive = \"reptile\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   nonreptile reptile\n  nonreptile         33       0\n  reptile            15       2\n                                          \n               Accuracy : 0.7             \n                 95% CI : (0.5539, 0.8214)\n    No Information Rate : 0.96            \n    P-Value [Acc > NIR] : 1.0000000       \n                                          \n                  Kappa : 0.1497          \n                                          \n Mcnemar's Test P-Value : 0.0003006       \n                                          \n            Sensitivity : 1.0000          \n            Specificity : 0.6875          \n         Pos Pred Value : 0.1176          \n         Neg Pred Value : 1.0000          \n             Prevalence : 0.0400          \n         Detection Rate : 0.0400          \n   Detection Prevalence : 0.3400          \n      Balanced Accuracy : 0.8438          \n                                          \n       'Positive' Class : reptile         \n                                          \n```\n:::\n:::\n\n\n**Note** that the accuracy is below the no information rate! However, kappa (improvement of accuracy over randomness) and sensitivity (the ability to identify reptiles) have increased.\n\nThere is a tradeoff between sensitivity and specificity (how many of the identified animals are really reptiles) The tradeoff can be controlled using the sample proportions. We can sample more reptiles to increase sensitivity at the cost of lower specificity (this effect cannot be seen in the data since the test set has only a few reptiles).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nid <- strata(training_reptile, stratanames = \"type\", size = c(50, 100), method = \"srswr\")\ntraining_reptile_balanced <- training_reptile |> \n  slice(id$ID_unit)\ntable(training_reptile_balanced$type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nnonreptile    reptile \n        50        100 \n```\n:::\n\n```{.r .cell-code}\nfit <- training_reptile_balanced |> \n  train(type ~ .,\n        data = _,\n        method = \"rpart\",\n        trControl = trainControl(method = \"cv\"),\n        control = rpart.control(minsplit = 5))\n\nconfusionMatrix(data = predict(fit, testing_reptile),\n                ref = testing_reptile$type, positive = \"reptile\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   nonreptile reptile\n  nonreptile         33       0\n  reptile            15       2\n                                          \n               Accuracy : 0.7             \n                 95% CI : (0.5539, 0.8214)\n    No Information Rate : 0.96            \n    P-Value [Acc > NIR] : 1.0000000       \n                                          \n                  Kappa : 0.1497          \n                                          \n Mcnemar's Test P-Value : 0.0003006       \n                                          \n            Sensitivity : 1.0000          \n            Specificity : 0.6875          \n         Pos Pred Value : 0.1176          \n         Neg Pred Value : 1.0000          \n             Prevalence : 0.0400          \n         Detection Rate : 0.0400          \n   Detection Prevalence : 0.3400          \n      Balanced Accuracy : 0.8438          \n                                          \n       'Positive' Class : reptile         \n                                          \n```\n:::\n:::\n\n\n### Option 3: Build A Larger Tree and use Predicted Probabilities\n\nIncrease complexity and require less data for splitting a node. Here I also use AUC (area under the ROC) as the tuning metric. You need to specify the two class summary function. Note that the tree still trying to improve accuracy on the data and not AUC! I also enable class probabilities since I want to predict probabilities later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- training_reptile |> \n  train(type ~ .,\n        data = _,\n        method = \"rpart\",\n        tuneLength = 10,\n        trControl = trainControl(method = \"cv\",\n        classProbs = TRUE,  ## necessary for predict with type=\"prob\"\n        summaryFunction=twoClassSummary),  ## necessary for ROC\n        metric = \"ROC\",\n        control = rpart.control(minsplit = 3))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n```\n:::\n\n```{.r .cell-code}\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n51 samples\n16 predictors\n 2 classes: 'nonreptile', 'reptile' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 46, 47, 46, 46, 46, 45, ... \nResampling results:\n\n  ROC        Sens   Spec\n  0.3583333  0.975  0   \n\nTuning parameter 'cp' was held constant at a value of 0\n```\n:::\n\n```{.r .cell-code}\nrpart.plot(fit$finalModel, extra = 2)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-56-1.png){width=672}\n:::\n\n```{.r .cell-code}\nconfusionMatrix(data = predict(fit, testing_reptile),\n                ref = testing_reptile$type, positive = \"reptile\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   nonreptile reptile\n  nonreptile         48       2\n  reptile             0       0\n                                          \n               Accuracy : 0.96            \n                 95% CI : (0.8629, 0.9951)\n    No Information Rate : 0.96            \n    P-Value [Acc > NIR] : 0.6767          \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : 0.4795          \n                                          \n            Sensitivity : 0.00            \n            Specificity : 1.00            \n         Pos Pred Value :  NaN            \n         Neg Pred Value : 0.96            \n             Prevalence : 0.04            \n         Detection Rate : 0.00            \n   Detection Prevalence : 0.00            \n      Balanced Accuracy : 0.50            \n                                          \n       'Positive' Class : reptile         \n                                          \n```\n:::\n:::\n\n\n**Note:** Accuracy is high, but it is close or below to the no-information rate!\n\n#### Create A Biased Classifier\n\nWe can create a classifier which will detect more reptiles at the expense of misclassifying non-reptiles. This is equivalent to increasing the cost of misclassifying a reptile as a non-reptile. The usual rule is to predict in each node the majority class from the test data in the node. For a binary classification problem that means a probability of \\>50%. In the following, we reduce this threshold to 1% or more. This means that if the new observation ends up in a leaf node with 1% or more reptiles from training then the observation will be classified as a reptile. The data set is small and this works better with more data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprob <- predict(fit, testing_reptile, type = \"prob\")\ntail(prob)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     nonreptile    reptile\ntuna  1.0000000 0.00000000\nvole  0.9615385 0.03846154\nwasp  0.5000000 0.50000000\nwolf  0.9615385 0.03846154\nworm  1.0000000 0.00000000\nwren  0.9615385 0.03846154\n```\n:::\n\n```{.r .cell-code}\npred <- as.factor(ifelse(prob[,\"reptile\"]>=0.01, \"reptile\", \"nonreptile\"))\n\nconfusionMatrix(data = pred,\n                ref = testing_reptile$type, positive = \"reptile\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   nonreptile reptile\n  nonreptile         13       0\n  reptile            35       2\n                                          \n               Accuracy : 0.3             \n                 95% CI : (0.1786, 0.4461)\n    No Information Rate : 0.96            \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.0289          \n                                          \n Mcnemar's Test P-Value : 9.081e-09       \n                                          \n            Sensitivity : 1.00000         \n            Specificity : 0.27083         \n         Pos Pred Value : 0.05405         \n         Neg Pred Value : 1.00000         \n             Prevalence : 0.04000         \n         Detection Rate : 0.04000         \n   Detection Prevalence : 0.74000         \n      Balanced Accuracy : 0.63542         \n                                          \n       'Positive' Class : reptile         \n                                          \n```\n:::\n:::\n\n\n**Note** that accuracy goes down and is below the no information rate. However, both measures are based on the idea that all errors have the same cost. What is important is that we are now able to find more reptiles.\n\n#### Plot the ROC Curve\n\nSince we have a binary classification problem and a classifier that predicts a probability for an observation to be a reptile, we can also use a [receiver operating characteristic (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve. For the ROC curve all different cutoff thresholds for the probability are used and then connected with a line. The area under the curve represents a single number for how well the classifier works (the closer to one, the better).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"pROC\")\nr <- roc(testing_reptile$type == \"reptile\", prob[,\"reptile\"])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = FALSE, case = TRUE\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting direction: controls < cases\n```\n:::\n\n```{.r .cell-code}\nr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nroc.default(response = testing_reptile$type == \"reptile\", predictor = prob[,     \"reptile\"])\n\nData: prob[, \"reptile\"] in 48 controls (testing_reptile$type == \"reptile\" FALSE) < 2 cases (testing_reptile$type == \"reptile\" TRUE).\nArea under the curve: 0.7656\n```\n:::\n\n```{.r .cell-code}\nggroc(r) + geom_abline(intercept = 1, slope = 1, color = \"darkgrey\")\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-58-1.png){width=672}\n:::\n:::\n\n\n### Option 4: Use a Cost-Sensitive Classifier\n\nThe implementation of CART in `rpart` can use a cost matrix for making splitting decisions (as parameter `loss`). The matrix has the form\n\nTP FP FN TN\n\nTP and TN have to be 0. We make FN very expensive (100).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncost <- matrix(c(\n  0,   1,\n  100, 0\n), byrow = TRUE, nrow = 2)\ncost\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    0    1\n[2,]  100    0\n```\n:::\n\n```{.r .cell-code}\nfit <- training_reptile |> \n  train(type ~ .,\n        data = _,\n        method = \"rpart\",\n        parms = list(loss = cost),\n        trControl = trainControl(method = \"cv\"))\n```\n:::\n\n\nThe warning \"There were missing values in resampled performance measures\" means that some folds did not contain any reptiles (because of the class imbalance) and thus the performance measures could not be calculates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n51 samples\n16 predictors\n 2 classes: 'nonreptile', 'reptile' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 46, 46, 46, 45, 46, 45, ... \nResampling results:\n\n  Accuracy   Kappa      \n  0.4766667  -0.03038961\n\nTuning parameter 'cp' was held constant at a value of 0\n```\n:::\n\n```{.r .cell-code}\nrpart.plot(fit$finalModel, extra = 2)\n```\n\n::: {.cell-output-display}\n![](rExercise3_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n\n```{.r .cell-code}\nconfusionMatrix(data = predict(fit, testing_reptile),\n                ref = testing_reptile$type, positive = \"reptile\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   nonreptile reptile\n  nonreptile         39       0\n  reptile             9       2\n                                          \n               Accuracy : 0.82            \n                 95% CI : (0.6856, 0.9142)\n    No Information Rate : 0.96            \n    P-Value [Acc > NIR] : 0.999975        \n                                          \n                  Kappa : 0.2574          \n                                          \n Mcnemar's Test P-Value : 0.007661        \n                                          \n            Sensitivity : 1.0000          \n            Specificity : 0.8125          \n         Pos Pred Value : 0.1818          \n         Neg Pred Value : 1.0000          \n             Prevalence : 0.0400          \n         Detection Rate : 0.0400          \n   Detection Prevalence : 0.2200          \n      Balanced Accuracy : 0.9062          \n                                          \n       'Positive' Class : reptile         \n                                          \n```\n:::\n:::\n\n\nThe high cost for false negatives results in a classifier that does not miss any reptile.\n\n**Note:** Using a cost-sensitive classifier is often the best option. Unfortunately, the most classification algorithms (or their implementation) do not have the ability to consider misclassification cost.\n",
    "supporting": [
      "rExercise3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}